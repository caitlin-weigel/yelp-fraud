---
title: "Yelp Analysis"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    theme: yeti
runtime: shiny
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidytext)
library(dplyr)
library(tibble)
library(ggplot2)
library(tidyr)
library(wordcloud)
library(reshape2)
```

```{r data-cleaning, message=FALSE, warning=FALSE, include=FALSE}
yelp <- read.csv("~/Desktop/yelp-fraud/Yelp.csv")

bad_reviews = which(yelp$difference_rating <= -1.5)
good_reviews = which(yelp$difference_rating >= 2)

# clean up the text
review_text <- as.character(yelp$review)
for (i in 1:103) {
  review_text[i] = as.character(review_text[i])
}
review_table <- as.data.frame(review_text)
review_table <- review_table %>% mutate(person = row_number())
reivew_table <- as.tibble(review_table)
review_table$review_text = as.character(review_table$review_text)
positive_review = review_table[c(good_reviews),]
negative_review = review_table[c(bad_reviews),]

positive_review <- positive_review %>% unnest_tokens(word, review_text)
negative_review <- negative_review %>% unnest_tokens(word, review_text)

common_reviews = which(yelp$difference_rating > -1.5 & yelp$difference_rating < 2)
common_review = review_table[c(common_reviews),]
common_review <- common_review %>% unnest_tokens(word, review_text)
```

Words Frequency {data-orientation=columns}
=======================================================================

Column {data-width=500}
-----------------------------------------------------------------------

### Overrated Fraudulent Reviews

```{r}
data(stop_words)
positive_review <- positive_review %>% anti_join(stop_words)

positive_count <- positive_review %>% count(word, sort = TRUE) %>% top_n(15) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip()
positive_count
```

Column {data-width=500}
-----------------------------------------------------------------------

### Underrated Fraudulent Reviews

```{r}
negative_review <- negative_review %>% anti_join(stop_words)

negative_count <- negative_review %>% count(word, sort = TRUE) %>% top_n(15) %>% mutate(word = reorder(word, n)) %>% ggplot(aes(word, n)) + geom_col() + xlab(NULL) + coord_flip()
negative_count
```

Spread of Sentiments {data-orientation=columns}
=======================================================================

Column {data-width=500}
-----------------------------------------------------------------------

### Overrated Fraudulent Reviews

```{r}
positive_sentiment <- positive_review %>% inner_join(get_sentiments("bing")) %>% count(person, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
positive_spread <- ggplot(positive_sentiment, aes(person, sentiment)) +
  geom_col(show.legend = FALSE)
positive_spread
```

### Underrated Fraudulent Reviews

```{r}
negative_sentiment <- negative_review %>% inner_join(get_sentiments("bing")) %>% count(person, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
negative_spread <- ggplot(negative_sentiment, aes(person, sentiment)) +
  geom_col(show.legend = FALSE)
negative_spread
```

Column {data-width=500}
-----------------------------------------------------------------------

### Normal Reviews

```{r}
common_review <- common_review %>% anti_join(stop_words)
common_sentiment <- common_review %>% inner_join(get_sentiments("bing")) %>% count(person, sentiment) %>% spread(sentiment, n, fill = 0) %>% mutate(sentiment = positive - negative)
common_spread <- ggplot(common_sentiment, aes(person, sentiment)) +
  geom_col(show.legend = FALSE)
common_spread
```

### Calculation

Average of Sentiments: 
```{r}
type <- c("Overrated Fraudulent Reviews:", "Underrated Fraudulent Reviews:", "Common Reviews:")
average <- c(mean(positive_sentiment$sentiment), mean(negative_sentiment$sentiment), mean(common_sentiment$sentiment))
average_sentiment <- data.frame(Type = type, Average = average)
knitr::kable(average_sentiment)
```

Common Words with Sentiments {data-orientation=columns}
=======================================================================

Column {data-width=500}
-----------------------------------------------------------------------

### Overrated Fraudulent Reviews

```{r}
bing_word_counts_positive <- positive_review %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bing_word_counts_positive_graph <- bing_word_counts_positive %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
bing_word_counts_positive_graph
```

Column {data-width=500}
-----------------------------------------------------------------------

### Underrated Fraudulent Reviews

```{r}
bing_word_counts_negative <- negative_review %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bing_word_counts_negative_graph <- bing_word_counts_negative %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
bing_word_counts_negative_graph
```

Word Cloud {data-orientation=columns}
=======================================================================

Column {data-width=500}
-----------------------------------------------------------------------

### Overrated Fraudulent Reviews

```{r}
positive_review %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "blue"),
                   max.words = 100)
```

Column {data-width=500}
-----------------------------------------------------------------------

### Underrated Fraudulent Reviews

```{r}
negative_review %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("red", "blue"),
                   max.words = 100)
```


Shiny {data-orientation=columns}
=======================================================================
```{r, echo = FALSE}

  library(shiny)
  library(dplyr)
  library(tm)
  library(wordcloud)
  library(memoise)

  # The list of valid books
  stars <- list("1" = "1_star",
                "2" = "2_star",
                "3" = "3_star",
                "4" = "4_star",
                "5" = "5_star")
  
  # Using "memoise" to automatically cache the results
  getTermMatrix <- memoise(function(star) {
    # Careful not to let just any name slip in here; a
    # malicious user could manipulate this value.
    if (!(star %in% stars))
      stop("Invalild star rating.")
    
    text <- readLines(sprintf("./%s.csv", star),
                      encoding="UTF-8")
    
    #words <- restaurant_rating
    
    myCorpus = Corpus(VectorSource(text))
    myCorpus = tm_map(myCorpus, content_transformer(tolower))
    myCorpus = tm_map(myCorpus, removePunctuation)
    myCorpus = tm_map(myCorpus, removeNumbers)
    myCorpus = tm_map(myCorpus, removeWords,
                      c(stopwords("SMART"), "the", "and", "but"))
    
    myDTM = TermDocumentMatrix(myCorpus,
                               control = list(minWordLength = 1))
    
    m = as.matrix(myDTM)
    
    sort(rowSums(m), decreasing = TRUE)
  })
  
  
  # Define UI for application that draws a histogram
  ui <- fluidPage(
    # Application title
    titlePanel("Word Cloud"),
    
    sidebarLayout(
      # Sidebar with a slider and selection inputs
      sidebarPanel(
        selectInput("selection", "Choose a star level:",
                    choices = stars),
        actionButton("update", "Change"),
        hr(),
        sliderInput("freq",
                    "Minimum Frequency:",
                    min = 1,  max = 50, value = 15),
        sliderInput("max",
                    "Maximum Number of Words:",
                    min = 1,  max = 300,  value = 100)
      ),
      
      # Show Word Cloud
      mainPanel(
        plotOutput("plot")
      )
    )
  )
  
  # Define server logic required to draw a wordcloud
  server <- function(input, output, session) {
    # Define a reactive expression for the document term matrix
    terms <- reactive({
      # Change when the "update" button is pressed...
      input$update
      # ...but not for anything else
      isolate({
        withProgress({
          setProgress(message = "Processing reviews...")
          getTermMatrix(input$selection)
        })
      })
    })
    
    # Make the wordcloud drawing predictable during a session
    wordcloud_rep <- repeatable(wordcloud)
    
    output$plot <- renderPlot({
      v <- terms()
      wordcloud_rep(names(v), v, scale=c(4,0.5),
                    min.freq = input$freq, max.words=input$max,
                    colors=brewer.pal(8, "Dark2"))
    })
  }
  
  # Run the application 
  shinyApp(ui = ui, server = server)


```


